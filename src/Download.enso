from Standard.Base import all
import Standard.Base.System.Input_Stream.Input_Stream
from Standard.Table import all
from Standard.Database import all
from Standard.AWS import all
from Standard.Google_Api import all
from Standard.Snowflake import all
import Standard.Visualization

polyglot java import org.w3c.tidy.Tidy
polyglot java import java.io.StringReader

type Page
    Info url:Text text:Text refs:(Vector Text)

    download_extract url url_prefix (limit=Nothing:Nothing|Integer) =
        IO.println "Fetching "+url.to_text
        operator50103 = Data.fetch url
        IO.println "Done fetching "+url.to_text
        text = operator50103.decode_as_text
        operator39794 = text.lines
        operator75987 = 'href="('+url_prefix+'[^\"]+)[^>]*>'
        operator15026 = operator75987.to_regex
        operator42699 = operator39794.filter (Filter_Condition.Contains url_prefix)
        operator52211 = operator15026.match
        operator96845 = operator42699.map operator52211
        operator86202 = operator96845.distinct
        operator48961 = operator86202.filter Filter_Condition.Not_Nothing
        event_list = operator48961.map m-> m.at 1
        operator14852 = event_list.distinct

        refs = if limit.is_nothing then operator14852 else
            operator14852 . take limit

        Page.Info url text refs

type Race
    Info event:Page race:Text ~results

xml_from_text text:Text -> XML_Document =
    r = StringReader.new text
    parser = Tidy.new
    parser.setXHTML True
    dom = parser.parseDOM r Nothing
    XML_Document.new dom

download_results event:Page race:Text =
    competition = race
    IO.println "Competition Fetching "+competition.to_text
    operator32357 = Data.fetch competition
    IO.println "Competition Done fetching "+competition.to_text
    html_text = operator32357.decode_as_text
    res = if html_text.contains "No results found for this competition." then Nothing else
        Download.parse_results competition html_text
    res

parse_results competition html_text =
    operator1419 = html_text.lines
    operator29807 = operator1419.find t-> t.contains "<title>"
    operator80108 = operator29807.replace (regex "</?title>") ''
    operator45914 = operator1419.find t-> t.contains 'class=\"date__short\"'
    operator3502 = operator45914.replace (regex "^.*?>|<.*?$") ''
    operator80228 = operator3502.parse_date 'MMM d, yyyy'
    operator93666 = operator1419.to_table
    operator49875 = operator93666.add_row_number from=0
    operator70297 = operator1419.index_of t-> t.contains '#events-info-results\"'
    operator27041 = operator49875.filter 'Row' (Filter_Condition.Equal_Or_Greater operator70297)
    operator43989 = operator27041.set (expr 'if contains([Value], \"<a class=\"\"table-row\") then 1 else Nothing') 'RowChange'
    operator45124 = operator43989.at 'RowChange'
    operator15701 = operator45124.running Statistic.Sum 'RowID'
    operator62604 = operator43989.set operator15701
    operator56965 = operator62604.set (expr 'if contains([Value], \"</a>\") then -1 else Nothing') 'RowEnd'
    operator33825 = operator56965.fill_nothing ['RowChange'] (Column_Ref.Name 'RowEnd')
    operator39679 = operator33825.at 'RowChange'
    operator55617 = operator39679.running Statistic.Sum 'RowState'
    operator19058 = operator33825.set operator55617
    operator8036 = operator19058.filter 'RowState' (Filter_Condition.Equal 1)
    operator93440 = operator8036.aggregate ['RowID'] [Aggregate_Column.Concatenate 'Value' 'HTML']
    operator66119 = operator93440.at 'HTML'
    operator16709 = operator66119 + "</a>"
    operator34690 = x-> x.get_xpath 'a/div/div/div' . map n->n.text.trim
    operator57467 = operator1419.index_of t-> t.contains 'id=\"events-info-results\"'
    operator710 = operator57467 - 1
    operator38009 = operator27041.filter 'Row' (Filter_Condition.Less operator710)
    operator42986 = operator38009.aggregate [] [Aggregate_Column.Concatenate separator='']
    operator91376 = operator42986.get_value
    operator84213 = xml_from_text (operator91376.replace "<br>" " " . replace "&nbsp;" " " . replace (regex "<!--.*?-->") "")
    operator2194 = operator84213.get_xpath 'div/div/div/div/div'
    operator80016 = operator2194.map n-> n.text.trim
    operator88173 = operator80016.to_table
    operator29547 = operator88173.add_row_number 'Field'
    operator76232 = operator16709.to_vector
    operator18288 = operator76232.map (t-> xml_from_text (t.replace "<br>" " " . replace "&nbsp;" " " . replace "&nbsp" " " . replace (regex "<!--.*?-->") ""))
    operator17654 = operator18288.map operator34690
    operator87908 = operator17654.map t->(if t == "" then Nothing else t)
    operator9307 = operator93440.set operator87908 'Values'
    operator26253 = operator9307.remove_columns ['HTML']
    operator75691 = operator26253.expand_to_rows 'Values'
    operator93423 = operator75691.add_row_number 'Field' group_by=['RowID']
    operator33244 = operator93423.join operator29547 Join_Kind.Inner [(Join_Condition.Equals 'Field')]
    operator24575 = operator33244.cross_tab ['RowID'] 'Value' (Aggregate_Column.First 'Values')
    operator24493 = operator24575.set operator80108 'Event Name'
    table = operator24493.set operator80228 'Date'

    competition_name = "race-" + (competition.split "=" . last) + ".csv"
    single_file = enso_project.data/competition_name
    result = table.write single_file

    IO.println "Competition "+competition.to_text+" stored in "+result.to_text

    table

download (limit:Nothing|Integer) =
    season = "2024"
    file = enso_project.data / ('FISResults'+season+'.csv')

    IO.println "Downloading snowboarding "+season.to_text+" into "+file.to_text

    url = "https://www.fis-ski.com/DB/snowboard/alpine-snowboard/calendar-results.html?noselection=true&disciplinecode=SG%2CPGS%2CPSL%2CGS%2CSL%2CPRT&seasoncode="+season

    event_list = Page.download_extract url "https://www.fis-ski.com/DB/general/event-details.html" limit
    race_info_list = event_list.refs.flat_map ev_url->
        ev = Page.download_extract ev_url "https://www.fis-ski.com/DB/general/results.html"
        ev.refs.map (r -> Race.Info ev r (Download.download_results ev r))

    valid_races = race_info_list.filter p->p.results.is_nothing.not
    with_race_ids = valid_races.map p-> p.results.set (p.race.split "=" . last) "RaceID"
    operator93079 = with_race_ids.map t-> t.rename_columns (t.column_names.map .trim)
    operator21858 = Table.from_union operator93079 match_columns=Match_Columns.By_Name
    operator13633 = operator21858.parse
    operator62651 = race_info_list.filter p->p.results.is_nothing
    operator88386 = operator62651.map .event
    result = operator13633.write file
    IO.println "Finished "+result.to_text

main limit=Nothing =
    download limit
